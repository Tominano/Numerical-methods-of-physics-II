Infok:
- Ez a magyar nyelv≈± v√°ltozat, m√©g le kell majd ford√≠tani. 
- Bem√°soltam a t√∂rzsanyagot, ebb≈ël k√©ne kiidulni a megold√°s implement√°ci√≥kkal √©s k√∂zben √°t√≠rni kicsit, plusz v√°ltoztatni/kieg√©sz√≠teni ahol j√≥nak l√°tjuk
- Vscodban szerintem sim√°n tudjuk szerkeszteni, tedd fel ezt [Markdown+Math](https://marketplace.visualstudio.com/items?itemName=goessner.mdmath) a plugint √©s jobb fel√ºl van egy Open preview to the Side gomb, de √°tt√©rhet√ºnk latexba is, ha √∫gy k√©nyelmesebb

ToDo:
- [ ] √Åltal√°nos megold√°s m√°sodfok√∫ illeszt√©s√©re (5. feladat) (Kapolcs)
- [ ] 3ùúé -n√°l jobban kil√≥g√≥ pontok elhagy√°s√°val, k√©t l√©p√©sben, illetve iterat√≠v m√≥don v√©gzi el a parabolailleszt√©st
- [ ] Illesztett param√©terek aszimptotikus hib√°ja (python implement√°ci√≥)
- [ ] Hibabecsl√©s a bootstrap m√≥dszerrel (Python implement√°ci√≥)


# F√ºggv√©nyilleszt√©s a line√°ris $\chi^2$ m√≥dszerrel


A line√°ris $\chi^2$-illeszt√©s m√≥dszere olyan modellek param√©tereinek meghat√°roz√°s√°ra alkalmas, ahol az illesztend≈ë f√ºggv√©ny fel√≠rhat√≥ tetsz≈ëleges f√ºggv√©nyek line√°rkombin√°ci√≥jak√©nt, felt√©ve, hogy az illeszt√©si param√©terek csak a line√°rkombin√°ci√≥ egy√ºtthat√≥inak szerep√©t t√∂ltik be, vagyis

$$ y(\mathbf{a}, \mathbf{x}) = \sum_k a_k f_k(\mathbf{x}), $$

ahol $\mathbf{a}$ a keresett param√©terekb≈ël alkotott vektor vektor, $\mathbf{x}$ pedig a f√ºggetlen v√°ltoz√≥. Tov√°bbi felt√©tel, hogy az $f_k(\mathbf{x})$ t√∂bbv√°ltoz√≥s f√ºggv√©nyek az √∂sszes $\textbf{x}$ m√©r√©si pontban ki√©rt√©kelhet≈ëk legyenek. Amennyiben a m√©r√©si hiba gauss-i, √∫gy az $y_i$ m√©rt √©rt√©kek hib√°j√°t egy $\sigma_i$ √©rt√©kkel jellemezhetj√ºk, ahol az $i$ index a m√©r√©si pontokon fut. A f√ºggv√©nyilleszt√©s j√≥s√°g√°t a

$$
\chi^2(\mathbf{a})
    = \sum_i \frac{\left[ y(\mathbf{a}, \mathbf{x}_i) - y_i \right]^2}{\sigma_i^2}
    = \sum_i \frac{\left[ \sum_k a_k f_k(\mathbf{x}_i) - y_i \right]^2}{\sigma_i^2}
$$

mennyis√©ggel jellemezhetj√ºk, mely Gauss-eloszl√°s√∫ hiba eset√©ben egzaktul k√∂vetkezik a _maximum likelihood_ m√≥dszerb≈ël. A legjobban illeszked≈ë modellre a $\chi^2$ kifejez√©s√©nek √©rt√©ke minim√°lis, azaz azokat az $a_k$ param√©tereket keress√ºk, melyek mellett $\chi^2$ parci√°lis deriv√°ltjai elt≈±nnek:

$$
\frac{\partial\chi^2(\mathbf{a})}{\partial a_k} = 0
$$

minden $a_k$-ra. A parci√°lis deriv√°ltakra √≠gy fel√≠rt egyenletrendszer √°ltal√°ban nem line√°ris, √≠gy a megold√°s√°ra k√∂zvetlen gy√∂kkeres≈ë m√≥dszerekkel nem sok es√©ly√ºnk van. Amennyiben azonban az $y(\mathbf{a}, \mathbf{x})$ modellt a fent bevezett line√°rkombin√°ci√≥ alakj√°ban adjuk meg, √∫gy k√∂nnyen bel√°that√≥, hogy a deriv√°ltak null√°v√° t√©tele a k√∂vezkez≈ë egyenletrendszerre vezet:

$$
\frac{\partial\chi^2(\mathbf{a})}{\partial a_k} =
    2 \cdot \sum_i \left[ \frac{1}{\sigma_i^2} \cdot 
        \left( 
            \sum_j a_j f_j(\mathbf{x}_i) - y_i
        \right) \cdot f_k(\mathbf{x}_i) \right] = 0.
$$

Ez m√°r line√°ris egyenletrendszer az $a_k$ egy√ºtthat√≥kra, hiszen az $y_i$ m√©rt √©rt√©kek √©s az $f_k(\mathbf{x}_i)$ b√°zisf√ºggv√©nyek az $\mathbf{x}_i$ m√©r√©si pontokban ismertek. K√∂nny≈± bel√°tni, hogy n√©mi √°t√≠r√°s ut√°n bevezethet≈ë egy $X_{ik}$, √∫n. tervm√°trix, √©s egy $b_i$ hib√°val reduk√°lt vektor:

$$
X_{ik} = \frac{f_k(\mathbf{x}_i)}{\sigma_i} \quad \quad \quad
b_i = \frac{y_i}{\sigma_i}.
$$

A parci√°lis deriv√°ltak null√°v√° t√©tel√©vel fel√≠rt egyenletrendszer ezekkel a jel√∂l√©sekkel

$$
\frac{\partial\chi^2(\mathbf{a})}{\partial a_k} =
    \sum_i \left[ \left( \sum_j a_j X_{ij} - b_i \right) X_{ik} \right] = 0
$$

alak√∫nak ad√≥dik, mely √°trendez√©s ut√°n 

$$
\sum_i \sum_j X_{ij} X_{ik} a_j  = \sum_i X_{ik} b_i,
$$

vagy m√°trixos √≠r√°sm√≥ddal

$$
\mathbf{X}^{T} \mathbf{X} \mathbf{a} = \mathbf{X}^{T} \mathbf{b}
$$

alakot √∂lt. Az egyenletet $\mathbf{a}$-ra megoldva megkapjuk a $\chi^2$-et minimaliz√°l√≥ param√©tereket.

## A reduk√°lt $\chi^2$

Mivel a $\chi^2$-re fel√≠rt kifejez√©s f√ºgg a m√©r√©si pontok sz√°m√°t√≥l, ez√©rt a $\chi^2$ √©rt√©ke nem haszn√°lhat√≥ arra, hogy k√©t, k√ºl√∂nb√∂z≈ë m√©r√©si sorozat eset√©ben meg√°llap√≠tsuk, hogy ugyanaz a modell mennyire j√≥l illeszkedik az egyik vagy m√°sik adatsorra. √âppen ez√©rt √©rdemes bevezetni a reduk√°lt $\chi^2$ nev≈± mennyis√©get:

$$
\chi^2_\nu = \frac{\chi^2}{\nu},
$$

ahol $\nu = N - M$ a szabads√°gi fokok sz√°ma, azaz a m√©r√©si adatpontok sz√°ma m√≠nusz az illesztend≈ë param√©terek sz√°ma. J√≥ illeszt√©sr≈ël akkor besz√©lhet√ºnk, ha $\chi^2_\nu \approx 1$.

## Az illesztett param√©terek aszimptotikus hib√°ja

A line√°ris $\chi^2$ m√≥dszerrel illesztett modellek param√©tereinek hib√°j√°t √∫gy becs√ºlthetj√ºk meg, hogy tekintj√ºk a $\chi^2(\mathbf{a})$ f√ºggv√©ny m√°sodik parci√°lis deriv√°ltjaib√≥l alkotott m√°trixot, hiszen a $\chi^2$ kifejez√©s√©nek Taylor-sor√°ban az ennek megfelel≈ë tag nem t≈±nik el minimum k√∂rnyezet√©ben. Tekintve, hogy

$$
\frac{\partial^2 \chi^2(\mathbf{a})}{\partial a_k \partial a_l} =
    \sum_i X_{ij} X_{ik} = \sum_i \frac{f_k(\mathbf{x}_i) f_l(\mathbf{x}_i)}{\sigma_i^2} =
    \alpha_{kl},
$$

az √≠gy bevezett $\mathbf{\alpha} = \mathbf{X}^{T} \mathbf{X}$ szimmetrikus m√°trixr√≥l bel√°that√≥, hogy annak $\mathbf{C} = \mathbf{\alpha}^{-1}$ inverze, az √∫n. kovarianciam√°trix, j√≥l jellemzi az illesztett param√©terek hib√°j√°t √©s kovarianci√°j√°t. Az $a_k$ param√©ter hib√°ja egyszer≈±en $\sigma_{a_k}^2 = C_{kk}$, m√≠g az $a_k$ √©s $a_l$ param√©terek kovarianci√°ja a $ \textrm{cov}(a_k, a_l) = C_{kl}$ m√°trixelem. Az √≠gy kisz√°m√≠tott hib√°k √∫n. aszimptotikus hib√°k, hiszen csup√°n a $\chi^2$ fel√ºlet m√°sodrend≈± k√∂zel√≠t√©s√©t veszik figyelembe a minimumhely k√∂rnyezet√©ben.

## Hibabecsl√©s a bootstrap m√≥dszerrel

Az illesztett param√©terek hib√°j√°nak pontos megbecsl√©s√©t olyan Monte Carlo m√≥dszerrel v√©gezhetn√©nk el, mely k√©pes mintav√©telezni az illeszt√©si param√©terek pontos $p(\mathbf{a})$ egy√ºttes eloszl√°sf√ºggv√©ny√©t. Ehelyett egy gyakran haszn√°lt, egyszer≈±bb, de igen hasznos elj√°r√°s a [bootstrap](https://outdoors.stackexchange.com/questions/11709/whats-the-purpose-of-the-sling-on-the-heel-of-boots) m√≥dszer, ahol az illeszt√©st a m√©r√©si adatok egy v√©letlen r√©szhalmaz√°ra (pl. egyharmad√°ra) v√©gezz√ºk el, majd egy m√°sik v√©letlen r√©szhalmazt v√°lasztunk, mellyel ism√©t elv√©gezz√ºk az illeszt√©st, √©s √≠gy tov√°bb. Kell≈ëen sokszor megism√©telve az elj√°r√°st az illeszt√©si param√©terekre egy-egy eloszl√°st kapunk, melyeknek meghat√°rozhatjuk a v√°rhat√≥ √©rt√©k√©t, sz√≥r√°s√°t √©s kovarianci√°it. A legjobban illeszked≈ë modellparam√©tereknek tekinthetj√ºk az eloszl√°sok v√°rhat√≥ √©rt√©k√©t, m√≠g illeszt√©si hib√°nak a sz√≥r√°sukat.


## Irodalomjegyz√©k

* Press, Teukolsky, Vetterling & Flannery: Numerical Recipes (in C), 3. kiad√°s, Cambridge University Press, 15.4. fejezet